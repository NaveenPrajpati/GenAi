{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d882c04d",
   "metadata": {},
   "source": [
    "# LangChain 1.0+ Introduction - create_agent & Quick Start\n",
    "\"\"\"\n",
    "=====================================================================\n",
    "LangChain 1.0+ Quick Start Guide\n",
    "=====================================================================\n",
    "\n",
    "This notebook demonstrates the modern LangChain 1.0+ approach using\n",
    "the new `create_agent` function - the simplest way to build agents.\n",
    "\n",
    "Key Concepts Covered:\n",
    "--------------------\n",
    "1. create_agent() - The easiest way to build tool-using agents\n",
    "2. Tool definition with @tool decorator\n",
    "3. Agent invocation and message handling\n",
    "4. Understanding agent responses\n",
    "\n",
    "What's New in LangChain 1.0+:\n",
    "----------------------------\n",
    "- Simplified create_agent() replaces complex graph setup\n",
    "- Unified model initialization with init_chat_model()\n",
    "- Built-in tool calling support\n",
    "- Automatic message handling\n",
    "\n",
    "Architecture:\n",
    "-------------\n",
    "    User Message\n",
    "         â”‚\n",
    "         â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚  create_agent   â”‚  â† Simplified agent creation\n",
    "    â”‚  (model+tools)  â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â”œâ”€â”€â–º Tool Calls (if needed)\n",
    "         â”‚         â”‚\n",
    "         â”‚         â–¼\n",
    "         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚    â”‚  Tools   â”‚\n",
    "         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚         â”‚\n",
    "         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "    Final Response\n",
    "\n",
    "Updated for LangChain 1.0+ (2025-2026)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Environment Setup\n",
    "# =============================================================================\n",
    "# Load environment variables for API keys\n",
    "# Required: OPENAI_API_KEY (or other provider keys)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set API keys from environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"âœ… Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde858d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# create_agent() - The Simplest Way to Build Agents (LangChain 1.0+)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "create_agent() is the new unified way to create tool-using agents.\n",
    "It handles all the complexity of:\n",
    "- Tool binding\n",
    "- Message management\n",
    "- Tool execution loop\n",
    "- Response formatting\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "- model: str or ChatModel - The LLM to use (e.g., \"gpt-4o\", \"gpt-4.1\")\n",
    "- tools: List[Callable] - Functions decorated with @tool\n",
    "- system_prompt: str - Instructions for the agent\n",
    "- checkpointer: Optional - For conversation persistence\n",
    "- middleware: Optional - For advanced features like summarization\n",
    "\n",
    "Returns:\n",
    "--------\n",
    "An agent that can be invoked with messages\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Define Tools\n",
    "# =============================================================================\n",
    "# Tools are Python functions decorated with @tool\n",
    "# The docstring becomes the tool description for the LLM\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a given location.\n",
    "    \n",
    "    Args:\n",
    "        location: The city or location to get weather for (e.g., \"New York\", \"London\")\n",
    "    \n",
    "    Returns:\n",
    "        A string describing the current weather conditions\n",
    "    \"\"\"\n",
    "    # In production, this would call a weather API\n",
    "    return f\"The weather in {location} is sunny with a high of 75Â°F.\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., \"2 + 2\", \"10 * 5\")\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation for basic math\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Create the Agent\n",
    "# =============================================================================\n",
    "# create_agent combines model + tools + system prompt into a ready-to-use agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",              # Model to use (supports OpenAI, Anthropic, etc.)\n",
    "    tools=[get_weather, calculate],    # List of tool functions\n",
    "    system_prompt=\"You are a helpful assistant that can check weather and do calculations. \"\n",
    "                  \"Use the tools when needed to answer questions accurately.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created with tools:\", [t.name for t in [get_weather, calculate]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafba0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 3: Invoke the Agent\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Agent invocation accepts messages in multiple formats:\n",
    "1. Dict format: {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]}\n",
    "2. String format: {\"messages\": \"your question\"}\n",
    "3. HumanMessage format: {\"messages\": [HumanMessage(content=\"...\")]}\n",
    "\n",
    "The agent automatically:\n",
    "- Processes the user message\n",
    "- Decides if tools are needed\n",
    "- Executes tools if required\n",
    "- Returns a final response\n",
    "\"\"\"\n",
    "\n",
    "# Example 1: Weather query (will use get_weather tool)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Weather Query (Uses Tool)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in New York?\"}]\n",
    "})\n",
    "\n",
    "# The result contains the full message history\n",
    "print(f\"\\nðŸ“© Messages in response: {len(result['messages'])}\")\n",
    "\n",
    "# Let's examine each message\n",
    "for i, msg in enumerate(result['messages']):\n",
    "    msg_type = type(msg).__name__\n",
    "    content_preview = msg.content[:100] if msg.content else \"[No content - tool call]\"\n",
    "    print(f\"  {i+1}. {msg_type}: {content_preview}\")\n",
    "\n",
    "# Get the final answer\n",
    "final_answer = result['messages'][-1].content\n",
    "print(f\"\\nâœ… Final Answer: {final_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6065716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Example 2: Query Without Tool Use\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "When a question doesn't require tools, the agent responds directly.\n",
    "Notice the agent intelligently decides NOT to use the get_weather tool\n",
    "because \"australia\" is too broad - it needs a specific city.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Broad Query (Agent Decides No Tool Needed)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = agent.invoke({\"messages\": \"What is the weather in australia?\"})\n",
    "\n",
    "# Shorter response - no tool calls\n",
    "print(f\"\\nðŸ“© Messages: {len(result['messages'])}\")\n",
    "print(f\"\\nâœ… Response: {result['messages'][-1].content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a31ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Example 3: Using the Calculator Tool\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 3: Math Calculation (Uses Calculator Tool)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = agent.invoke({\"messages\": \"What is 15 * 7 + 23?\"})\n",
    "print(f\"\\nâœ… Response: {result['messages'][-1].content}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Example 4: Multi-Tool Query\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 4: Combined Query\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"What's the weather in Tokyo? Also, what is 100 divided by 4?\"\n",
    "})\n",
    "print(f\"\\nâœ… Response: {result['messages'][-1].content}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Summary: create_agent() Key Points\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "create_agent() - The Modern Way to Build Agents:\n",
    "------------------------------------------------\n",
    "\n",
    "âœ… SIMPLEST APPROACH:\n",
    "   agent = create_agent(model=\"gpt-4o-mini\", tools=[...], system_prompt=\"...\")\n",
    "\n",
    "âœ… AUTOMATIC FEATURES:\n",
    "   - Tool calling and execution\n",
    "   - Message history management\n",
    "   - Multi-turn conversations\n",
    "   - Error handling\n",
    "\n",
    "âœ… TOOL DEFINITION:\n",
    "   @tool\n",
    "   def my_tool(param: str) -> str:\n",
    "       '''Tool description (shown to LLM)'''\n",
    "       return result\n",
    "\n",
    "âœ… INVOCATION FORMATS:\n",
    "   agent.invoke({\"messages\": \"question\"})\n",
    "   agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]})\n",
    "\n",
    "âœ… RESPONSE STRUCTURE:\n",
    "   result[\"messages\"] -> List of all messages (Human, AI, Tool)\n",
    "   result[\"messages\"][-1].content -> Final answer\n",
    "\n",
    "Next Steps:\n",
    "-----------\n",
    "- 2-modelIntegration.ipynb: Different model providers\n",
    "- 3-tools.ipynb: Advanced tool patterns\n",
    "- 4-messages.ipynb: Message types and formatting\n",
    "- 5-structureoutput.ipynb: Structured outputs with Pydantic\n",
    "- 6-middleware.ipynb: Summarization and advanced features\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“š Summary: create_agent() is the simplest way to build agents!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
