{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Agents - Autonomous LLM Systems (LangChain 1.0+)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "=====================================================================\n",
    "LangChain Agents - LLMs That Take Actions\n",
    "=====================================================================\n",
    "\n",
    "What is an Agent?\n",
    "-----------------\n",
    "An agent is an LLM that can:\n",
    "- Decide which tools to use\n",
    "- Execute tools to gather information\n",
    "- Reason about results\n",
    "- Loop until task is complete\n",
    "\n",
    "Unlike chains (fixed sequence), agents are dynamic - the LLM decides\n",
    "the execution path based on the task.\n",
    "\n",
    "Agent Loop:\n",
    "-----------\n",
    "    User Query\n",
    "         â”‚\n",
    "         â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   LLM + Tools   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   (Reasoning)   â”‚                    â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "         â”‚                                 â”‚\n",
    "         â–¼                                 â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "    â”‚  Tool Call?     â”‚                    â”‚\n",
    "    â”‚  (Yes/No)       â”‚                    â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "         â”‚                                 â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                            â”‚\n",
    "    â”‚         â”‚                            â”‚\n",
    "   Yes        No                           â”‚\n",
    "    â”‚         â”‚                            â”‚\n",
    "    â–¼         â–¼                            â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
    "â”‚Executeâ”‚  â”‚Final      â”‚                   â”‚\n",
    "â”‚Tool   â”‚  â”‚Answer     â”‚                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "    â”‚                                      â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "LangChain 1.0+ Agent Methods:\n",
    "-----------------------------\n",
    "1. create_agent() - Standard way (recommended)\n",
    "2. Manual agent loop - Full control\n",
    "3. LangGraph - Complex multi-step agents\n",
    "\n",
    "Updated for LangChain 1.0+ (2025-2026)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "print(\"âœ… Environment configured for agent examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde858d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 1: Creating Tools\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Tools - The Agent's Capabilities\n",
    "---------------------------------\n",
    "Tools are functions that agents can call to interact with the world.\n",
    "\n",
    "The @tool decorator:\n",
    "- Uses function name as tool name\n",
    "- Uses docstring as tool description (IMPORTANT for LLM!)\n",
    "- Generates schema from type hints\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import random\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: Creating Tools\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simple tool - function signature defines schema\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a city.\n",
    "    \n",
    "    Args:\n",
    "        city: The city name (e.g., 'London', 'New York')\n",
    "    \n",
    "    Returns:\n",
    "        Current weather conditions\n",
    "    \"\"\"\n",
    "    # Simulated weather data\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n",
    "    temp = random.randint(0, 35)\n",
    "    return f\"{city}: {random.choice(conditions)}, {temp}Â°C\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression (e.g., '2 + 2', '100 * 5')\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation (in production, use a proper math parser)\n",
    "        result = eval(expression)\n",
    "        return f\"{expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the internal knowledge base for information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "    \n",
    "    Returns:\n",
    "        Relevant information from the knowledge base\n",
    "    \"\"\"\n",
    "    # Simulated knowledge base\n",
    "    kb = {\n",
    "        \"langchain\": \"LangChain is a framework for building LLM applications.\",\n",
    "        \"python\": \"Python is a high-level programming language.\",\n",
    "        \"agent\": \"An agent is an LLM that can use tools to accomplish tasks.\"\n",
    "    }\n",
    "    \n",
    "    for key, value in kb.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return \"No relevant information found.\"\n",
    "\n",
    "# List of tools\n",
    "tools = [get_weather, calculate, search_knowledge_base]\n",
    "\n",
    "print(f\"\\nðŸ”§ Created {len(tools)} tools:\")\n",
    "for t in tools:\n",
    "    print(f\"   - {t.name}: {t.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 2: create_agent() - The Standard Way (LangChain 1.0+)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "create_agent() Function\n",
    "-----------------------\n",
    "The recommended way to create agents in LangChain 1.0+.\n",
    "\n",
    "Features:\n",
    "- Simple API\n",
    "- Built-in tool execution\n",
    "- Supports middleware\n",
    "- Checkpointing for persistence\n",
    "- Streaming support\n",
    "\n",
    "Note: create_agent() uses LangGraph internally for execution.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 2: create_agent() - Standard Method\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create agent with tools\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",  # Model name or model instance\n",
    "    tools=tools,\n",
    "    # Optional: Add system prompt\n",
    "    # system_prompt=\"You are a helpful assistant...\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Agent created with create_agent()\")\n",
    "\n",
    "# Test the agent\n",
    "print(\"\\nðŸ¤– Testing agent...\")\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in Tokyo?\")]\n",
    "})\n",
    "\n",
    "# Get the final response\n",
    "final_message = result[\"messages\"][-1]\n",
    "print(f\"\\nðŸ’¬ Agent response: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 3: Manual Agent Loop (Pure LangChain)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Manual Agent Loop\n",
    "-----------------\n",
    "Build an agent from scratch using just LangChain (no LangGraph).\n",
    "This gives you full control over the execution logic.\n",
    "\n",
    "Steps:\n",
    "1. Bind tools to model\n",
    "2. Send messages to model\n",
    "3. Check for tool calls\n",
    "4. Execute tools if needed\n",
    "5. Loop until no more tool calls\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 3: Manual Agent Loop\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0)\n",
    "\n",
    "# Bind tools to model\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Create tool lookup dict\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "def execute_tool_calls(tool_calls: List[Dict]) -> List[ToolMessage]:\n",
    "    \"\"\"Execute tool calls and return ToolMessages.\"\"\"\n",
    "    results = []\n",
    "    for tc in tool_calls:\n",
    "        tool_name = tc[\"name\"]\n",
    "        tool_args = tc[\"args\"]\n",
    "        tool_id = tc[\"id\"]\n",
    "        \n",
    "        print(f\"   ðŸ”§ Executing: {tool_name}({tool_args})\")\n",
    "        \n",
    "        if tool_name in tools_dict:\n",
    "            result = tools_dict[tool_name].invoke(tool_args)\n",
    "        else:\n",
    "            result = f\"Error: Tool '{tool_name}' not found\"\n",
    "        \n",
    "        print(f\"   ðŸ“¤ Result: {result}\")\n",
    "        results.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_agent(user_input: str, max_iterations: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Run the agent loop manually.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's question\n",
    "        max_iterations: Safety limit on tool execution cycles\n",
    "    \n",
    "    Returns:\n",
    "        The agent's final response\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant with access to tools.\"),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nðŸ‘¤ User: {user_input}\")\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        print(f\"\\nðŸ”„ Iteration {i+1}\")\n",
    "        \n",
    "        # Get model response\n",
    "        response = model_with_tools.invoke(messages)\n",
    "        messages.append(response)\n",
    "        \n",
    "        # Check if model wants to use tools\n",
    "        if not response.tool_calls:\n",
    "            print(f\"\\nâœ… Final answer reached\")\n",
    "            return response.content\n",
    "        \n",
    "        # Execute tools and add results\n",
    "        tool_results = execute_tool_calls(response.tool_calls)\n",
    "        messages.extend(tool_results)\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "# Test the manual agent\n",
    "answer = run_agent(\"What's 25 * 4 and what's the weather in Paris?\")\n",
    "print(f\"\\nðŸ’¬ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 4: Agent with Conversation Memory\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Agents with Memory\n",
    "------------------\n",
    "Maintain conversation history across turns.\n",
    "The agent remembers previous questions and answers.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 4: Agent with Conversation Memory\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class ConversationalAgent:\n",
    "    \"\"\"Agent that maintains conversation history.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_with_tools, tools_dict):\n",
    "        self.model = model_with_tools\n",
    "        self.tools = tools_dict\n",
    "        self.history = [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Remember our conversation.\")\n",
    "        ]\n",
    "    \n",
    "    def chat(self, user_input: str, max_iterations: int = 5) -> str:\n",
    "        \"\"\"Process a chat turn with memory.\"\"\"\n",
    "        self.history.append(HumanMessage(content=user_input))\n",
    "        \n",
    "        for _ in range(max_iterations):\n",
    "            response = self.model.invoke(self.history)\n",
    "            self.history.append(response)\n",
    "            \n",
    "            if not response.tool_calls:\n",
    "                return response.content\n",
    "            \n",
    "            # Execute tools\n",
    "            for tc in response.tool_calls:\n",
    "                if tc[\"name\"] in self.tools:\n",
    "                    result = self.tools[tc[\"name\"]].invoke(tc[\"args\"])\n",
    "                else:\n",
    "                    result = \"Tool not found\"\n",
    "                self.history.append(ToolMessage(content=str(result), tool_call_id=tc[\"id\"]))\n",
    "        \n",
    "        return \"Max iterations reached\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Reset conversation history.\"\"\"\n",
    "        self.history = [self.history[0]]  # Keep system message\n",
    "\n",
    "# Create conversational agent\n",
    "conv_agent = ConversationalAgent(model_with_tools, tools_dict)\n",
    "\n",
    "# Multi-turn conversation\n",
    "conversation = [\n",
    "    \"What's the weather in London?\",\n",
    "    \"How about New York?\",\n",
    "    \"Which city is warmer based on what you told me?\"\n",
    "]\n",
    "\n",
    "for user_msg in conversation:\n",
    "    print(f\"\\nðŸ‘¤ User: {user_msg}\")\n",
    "    response = conv_agent.chat(user_msg)\n",
    "    print(f\"ðŸ¤– Agent: {response}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 5: Tool with Pydantic Schema\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Complex Tools with Pydantic\n",
    "---------------------------\n",
    "For tools with complex inputs, use Pydantic models.\n",
    "This provides validation and better documentation.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 5: Tools with Pydantic Schema\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class FlightSearchInput(BaseModel):\n",
    "    \"\"\"Input for flight search.\"\"\"\n",
    "    origin: str = Field(..., description=\"Origin airport code (e.g., 'JFK', 'LAX')\")\n",
    "    destination: str = Field(..., description=\"Destination airport code\")\n",
    "    date: str = Field(..., description=\"Travel date in YYYY-MM-DD format\")\n",
    "    passengers: int = Field(default=1, description=\"Number of passengers\", ge=1, le=9)\n",
    "\n",
    "@tool(args_schema=FlightSearchInput)\n",
    "def search_flights(origin: str, destination: str, date: str, passengers: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Search for available flights between two airports.\n",
    "    \n",
    "    Returns flight options with prices.\n",
    "    \"\"\"\n",
    "    # Simulated flight search\n",
    "    prices = [random.randint(200, 800) for _ in range(3)]\n",
    "    return f\"\"\"Flights {origin} â†’ {destination} on {date}:\n",
    "    1. Morning (8:00 AM): ${prices[0]} per person\n",
    "    2. Afternoon (2:00 PM): ${prices[1]} per person  \n",
    "    3. Evening (7:00 PM): ${prices[2]} per person\n",
    "    Total for {passengers} passenger(s): ${min(prices) * passengers} - ${max(prices) * passengers}\"\"\"\n",
    "\n",
    "# Test the tool\n",
    "print(\"\\nðŸ“‹ Tool Schema:\")\n",
    "print(f\"   {search_flights.args_schema.schema()}\")\n",
    "\n",
    "print(\"\\nðŸ”§ Direct tool call:\")\n",
    "result = search_flights.invoke({\n",
    "    \"origin\": \"JFK\",\n",
    "    \"destination\": \"LAX\",\n",
    "    \"date\": \"2025-03-15\",\n",
    "    \"passengers\": 2\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 6: Agent with Guardrails\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Adding Guardrails to Agents\n",
    "---------------------------\n",
    "Implement safety constraints:\n",
    "- Input validation\n",
    "- Tool restrictions\n",
    "- Output filtering\n",
    "- Iteration limits\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 6: Agent with Guardrails\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class GuardedAgent:\n",
    "    \"\"\"Agent with safety guardrails.\"\"\"\n",
    "    \n",
    "    BLOCKED_TOPICS = [\"password\", \"credit card\", \"ssn\", \"hack\"]\n",
    "    MAX_ITERATIONS = 5\n",
    "    MAX_TOOL_CALLS_PER_TURN = 3\n",
    "    \n",
    "    def __init__(self, model_with_tools, tools_dict):\n",
    "        self.model = model_with_tools\n",
    "        self.tools = tools_dict\n",
    "    \n",
    "    def validate_input(self, user_input: str) -> tuple[bool, str]:\n",
    "        \"\"\"Check if input is safe to process.\"\"\"\n",
    "        input_lower = user_input.lower()\n",
    "        for topic in self.BLOCKED_TOPICS:\n",
    "            if topic in input_lower:\n",
    "                return False, f\"âš ï¸ Cannot process requests about '{topic}'\"\n",
    "        return True, \"\"\n",
    "    \n",
    "    def validate_tool_calls(self, tool_calls: List) -> List:\n",
    "        \"\"\"Limit and validate tool calls.\"\"\"\n",
    "        return tool_calls[:self.MAX_TOOL_CALLS_PER_TURN]\n",
    "    \n",
    "    def run(self, user_input: str) -> Dict[str, Any]:\n",
    "        \"\"\"Run agent with guardrails.\"\"\"\n",
    "        # Guardrail 1: Validate input\n",
    "        is_valid, error_msg = self.validate_input(user_input)\n",
    "        if not is_valid:\n",
    "            return {\"success\": False, \"response\": error_msg, \"tool_calls\": 0}\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Be concise.\"),\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "        \n",
    "        total_tool_calls = 0\n",
    "        \n",
    "        # Guardrail 2: Iteration limit\n",
    "        for iteration in range(self.MAX_ITERATIONS):\n",
    "            response = self.model.invoke(messages)\n",
    "            messages.append(response)\n",
    "            \n",
    "            if not response.tool_calls:\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"response\": response.content,\n",
    "                    \"tool_calls\": total_tool_calls,\n",
    "                    \"iterations\": iteration + 1\n",
    "                }\n",
    "            \n",
    "            # Guardrail 3: Limit tool calls per turn\n",
    "            limited_calls = self.validate_tool_calls(response.tool_calls)\n",
    "            total_tool_calls += len(limited_calls)\n",
    "            \n",
    "            for tc in limited_calls:\n",
    "                result = self.tools[tc[\"name\"]].invoke(tc[\"args\"]) if tc[\"name\"] in self.tools else \"Error\"\n",
    "                messages.append(ToolMessage(content=str(result), tool_call_id=tc[\"id\"]))\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"response\": \"Max iterations reached\",\n",
    "            \"tool_calls\": total_tool_calls\n",
    "        }\n",
    "\n",
    "# Test guarded agent\n",
    "guarded_agent = GuardedAgent(model_with_tools, tools_dict)\n",
    "\n",
    "# Safe request\n",
    "print(\"\\nâœ… Safe request:\")\n",
    "result = guarded_agent.run(\"What's the weather in Berlin?\")\n",
    "print(f\"   Response: {result['response']}\")\n",
    "print(f\"   Tool calls: {result['tool_calls']}\")\n",
    "\n",
    "# Blocked request\n",
    "print(\"\\nâŒ Blocked request:\")\n",
    "result = guarded_agent.run(\"What's my password?\")\n",
    "print(f\"   Response: {result['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Step 7: Streaming Agent Responses\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Streaming Agent Output\n",
    "----------------------\n",
    "Stream tokens as the agent generates its response.\n",
    "Shows both tool calls and final answer in real-time.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 7: Streaming Agent Responses\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "async def stream_agent(user_input: str):\n",
    "    \"\"\"Stream agent responses including tool calls.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nðŸ‘¤ User: {user_input}\")\n",
    "    print(\"\\nðŸ¤– Agent: \", end=\"\", flush=True)\n",
    "    \n",
    "    for _ in range(5):  # Max iterations\n",
    "        full_response = None\n",
    "        \n",
    "        async for chunk in model_with_tools.astream(messages):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            full_response = chunk\n",
    "        \n",
    "        if not full_response or not full_response.tool_calls:\n",
    "            print()  # Newline after streaming\n",
    "            break\n",
    "        \n",
    "        # Handle tool calls\n",
    "        messages.append(full_response)\n",
    "        print(f\"\\n   [Calling tools...]\")\n",
    "        \n",
    "        for tc in full_response.tool_calls:\n",
    "            result = tools_dict[tc[\"name\"]].invoke(tc[\"args\"]) if tc[\"name\"] in tools_dict else \"Error\"\n",
    "            print(f\"   ðŸ”§ {tc['name']}: {result}\")\n",
    "            messages.append(ToolMessage(content=str(result), tool_call_id=tc[\"id\"]))\n",
    "        \n",
    "        print(\"\\nðŸ¤– Agent: \", end=\"\", flush=True)\n",
    "\n",
    "# Run streaming agent\n",
    "await stream_agent(\"Calculate 100 / 4 and tell me the weather in Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Summary: Agents in LangChain 1.0+\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "=====================================================================\n",
    "KEY TAKEAWAYS - Agents in LangChain\n",
    "=====================================================================\n",
    "\n",
    "1. CREATE TOOLS:\n",
    "   --------------\n",
    "   from langchain_core.tools import tool\n",
    "   \n",
    "   @tool\n",
    "   def my_tool(arg: str) -> str:\n",
    "       '''Tool description (used by LLM)'''\n",
    "       return result\n",
    "\n",
    "2. USING create_agent() (RECOMMENDED):\n",
    "   ------------------------------------\n",
    "   from langchain.agents import create_agent\n",
    "   \n",
    "   agent = create_agent(\n",
    "       model=\"gpt-4o-mini\",\n",
    "       tools=[tool1, tool2]\n",
    "   )\n",
    "   result = agent.invoke({\"messages\": [HumanMessage(...)]})\n",
    "\n",
    "3. MANUAL AGENT LOOP:\n",
    "   -------------------\n",
    "   model_with_tools = model.bind_tools(tools)\n",
    "   \n",
    "   while True:\n",
    "       response = model_with_tools.invoke(messages)\n",
    "       if not response.tool_calls:\n",
    "           break  # Got final answer\n",
    "       # Execute tools, add results, continue\n",
    "\n",
    "4. TOOL EXECUTION:\n",
    "   ----------------\n",
    "   for tc in response.tool_calls:\n",
    "       result = tools_dict[tc[\"name\"]].invoke(tc[\"args\"])\n",
    "       messages.append(ToolMessage(\n",
    "           content=result,\n",
    "           tool_call_id=tc[\"id\"]\n",
    "       ))\n",
    "\n",
    "5. GUARDRAILS:\n",
    "   ------------\n",
    "   - Validate input before processing\n",
    "   - Limit tool calls per turn\n",
    "   - Set max iterations\n",
    "   - Filter sensitive content\n",
    "\n",
    "6. BEST PRACTICES:\n",
    "   ----------------\n",
    "   - Write clear tool descriptions (LLM reads them)\n",
    "   - Use temperature=0 for consistent tool calling\n",
    "   - Implement error handling in tools\n",
    "   - Add iteration limits (prevent infinite loops)\n",
    "   - Log tool calls for debugging\n",
    "\n",
    "Common Imports:\n",
    "---------------\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "=====================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Agents Module Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Agent Patterns:\n",
    "---------------\n",
    "1. create_agent() - Standard, recommended approach\n",
    "2. Manual loop - Full control, no LangGraph\n",
    "3. Conversational - With memory\n",
    "4. Guarded - With safety constraints\n",
    "\n",
    "For complex multi-agent systems, explore LangGraph!\n",
    "\n",
    "ðŸŽ‰ Congratulations! You've completed the LangChain tutorial series!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
